{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import math\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the files\n",
    "df_train = pd.read_csv(\"../CSV_files/sonar_train.csv\")\n",
    "df_test = pd.read_csv(\"../CSV_files/sonar_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manhattan Distance:  7.0\n",
      "Euclidean Distance:  5.0\n"
     ]
    }
   ],
   "source": [
    "# minkowski distance implementation\n",
    "def minkDist(q, a, b):\n",
    "    '''q = 1(man) or 2(euc); a and b are any same-sized tuples'''\n",
    "    z = []\n",
    "    zSum = 0\n",
    "    if (len(a) != len(b)): # checks tuples are of the same length\n",
    "        print(\"tuple length mismatch\")\n",
    "    else:      \n",
    "        for i in range(0, len(a)): # fills z with distance by plane, to the necessary power\n",
    "            z.append(abs(a[i]-b[i])**q)  \n",
    "        for j in range(0, len(z)): # sums all planar distances\n",
    "            zSum += z[j]\n",
    "        dist = zSum**(1/q) #uses the necessary root for the values\n",
    "            \n",
    "        return dist\n",
    "    \n",
    "a = (2,2)\n",
    "b = (5,6)\n",
    "\n",
    "print(\"Manhattan Distance: \", minkDist(1, a, b)) # 7 expected\n",
    "print(\"Euclidean Distance: \", minkDist(2, a, b)) # 5 expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest Neighbour:  (-4, 6)\n"
     ]
    }
   ],
   "source": [
    "# neighrest neighbour implementation\n",
    "def nN(distType, newObj, otherObjs):\n",
    "    '''newObj is a tuple, otherObjs is a list of tuples, returns nearest object'''\n",
    "    closestVal = sys.maxsize\n",
    "    closestObj = -1\n",
    "    for i in otherObjs:\n",
    "        dFromNew = minkDist(distType, newObj, i)\n",
    "        if (dFromNew < closestVal):\n",
    "            closestVal = dFromNew\n",
    "            closestObj = i\n",
    "    return closestObj\n",
    "\n",
    "a = (-4, 7)\n",
    "bs = ((0,0), (-3,5), (10,12), (-4,6), (2,-9)) \n",
    "\n",
    "print(\"Nearest Neighbour: \", nN(2, a, bs)) # (-4, 6) expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outer return type:  <class 'list'>\n",
      "inner return type:  <class 'tuple'>\n"
     ]
    }
   ],
   "source": [
    "def dfToTupList(df):\n",
    "    '''converts pandas dataframe to lists of rows, minus the Class Parameter'''\n",
    "    recList = list(df.to_records(index=False))\n",
    "    tupList = []\n",
    "    for obj in recList:\n",
    "        oVals = tuple(obj)[:-1]\n",
    "        tupList.append(oVals)\n",
    "    return(tupList)\n",
    "\n",
    "print(\"outer return type: \", type(dfToTupList(df_train))) # list expected\n",
    "print(\"inner return type: \", type(dfToTupList(df_train)[0])) # tuple expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions:  ['R', 'M', 'M', 'R', 'R', 'M', 'M', 'M', 'M', 'M', 'R', 'R', 'R', 'R', 'M', 'M', 'M', 'R', 'M', 'M', 'M', 'R', 'R', 'R', 'R', 'M', 'R', 'R', 'M', 'M', 'M', 'M', 'M', 'R', 'M', 'M', 'M', 'M', 'M', 'R', 'R', 'M', 'M', 'M', 'M', 'R', 'R', 'M', 'R', 'R', 'M', 'R', 'R', 'M', 'M', 'R', 'M', 'R', 'M', 'M', 'R', 'M', 'M', 'R', 'M', 'M', 'M', 'M', 'M']\n"
     ]
    }
   ],
   "source": [
    "def getPredictions(q, testList, trainList):\n",
    "    '''2 lists of tuples required'''\n",
    "    testPreds = []\n",
    "    for obj in testList:\n",
    "        closest = nN(q, obj, trainList)\n",
    "        index = trainList.index(closest) # indexes are the same, predicted class from the training data\n",
    "        testPreds.append(df_train[\"Class\"][index])\n",
    "    return(testPreds)\n",
    "\n",
    "print(\"Predictions: \", getPredictions(2, dfToTupList(df_test), dfToTupList(df_train))) #expected list of classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelEvaluator(predictions, actual):\n",
    "    '''returns model evaluation statistics - accuracy, sensitivity, specificity and precision'''\n",
    "    # \"True\" means correct, \"Positive\" means desireable (metal)\n",
    "    tp = tn = fp = fn = 0\n",
    "    for i in actual:\n",
    "        for j in predictions:\n",
    "            if (j == \"M\"):\n",
    "                if (j == i):\n",
    "                    tp +=1\n",
    "                elif (j != i):\n",
    "                    fp += 1\n",
    "            elif (j == \"R\"):\n",
    "                if (j == i):\n",
    "                    tn +=1\n",
    "                elif (j != i):\n",
    "                    fn += 1\n",
    "\n",
    "    totLen = tp + fp + tn + fn\n",
    "    # accuracy: \n",
    "    accScore = 100 * (tn+tp) / totLen\n",
    "    # sensitivity\n",
    "    senScore = 100 * tp / (tp + fn) \n",
    "    # specificity\n",
    "    speScore = 100 * tn / (tn + fp) \n",
    "    # precision\n",
    "    preScore = 100 * tp / (tp + fp)\n",
    "\n",
    "    print(\"accuracy: \", accScore, \"%\")\n",
    "    print(\"sensitivity: \", senScore, \"%\")\n",
    "    print(\"specificity: \", speScore, \"%\")\n",
    "    print(\"precision: \", preScore, \"%\")\n",
    "    \n",
    "    # to complete the task at the end of part 1b\n",
    "    return(accScore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainEval(q, testData, trainData):\n",
    "    \n",
    "    testList = dfToTupList(testData)\n",
    "    trainList = dfToTupList(trainData)\n",
    "    predList = getPredictions(q, testList, trainList)\n",
    "    acc = modelEvaluator(predList, df_test[\"Class\"])\n",
    "    \n",
    "    return(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q= 1 : \n",
      "accuracy:  49.45261182358461 %\n",
      "sensitivity:  42.44604316546763 %\n",
      "specificity:  57.55395683453237 %\n",
      "precision:  53.6231884057971 %\n",
      "q= 2 : \n",
      "accuracy:  49.40047961630695 %\n",
      "sensitivity:  41.726618705035975 %\n",
      "specificity:  58.273381294964025 %\n",
      "precision:  53.6231884057971 %\n",
      "q= 3 : \n",
      "accuracy:  49.40047961630695 %\n",
      "sensitivity:  41.726618705035975 %\n",
      "specificity:  58.273381294964025 %\n",
      "precision:  53.6231884057971 %\n",
      "q= 4 : \n",
      "accuracy:  49.29621520175164 %\n",
      "sensitivity:  40.28776978417266 %\n",
      "specificity:  59.71223021582734 %\n",
      "precision:  53.6231884057971 %\n",
      "q= 5 : \n",
      "accuracy:  49.244082994473985 %\n",
      "sensitivity:  39.568345323741006 %\n",
      "specificity:  60.431654676258994 %\n",
      "precision:  53.6231884057971 %\n",
      "q= 6 : \n",
      "accuracy:  49.244082994473985 %\n",
      "sensitivity:  39.568345323741006 %\n",
      "specificity:  60.431654676258994 %\n",
      "precision:  53.6231884057971 %\n",
      "q= 7 : \n",
      "accuracy:  49.19195078719633 %\n",
      "sensitivity:  38.84892086330935 %\n",
      "specificity:  61.15107913669065 %\n",
      "precision:  53.6231884057971 %\n",
      "q= 8 : \n",
      "accuracy:  49.19195078719633 %\n",
      "sensitivity:  38.84892086330935 %\n",
      "specificity:  61.15107913669065 %\n",
      "precision:  53.6231884057971 %\n",
      "q= 9 : \n",
      "accuracy:  49.244082994473985 %\n",
      "sensitivity:  39.568345323741006 %\n",
      "specificity:  60.431654676258994 %\n",
      "precision:  53.6231884057971 %\n",
      "q= 10 : \n",
      "accuracy:  49.29621520175164 %\n",
      "sensitivity:  40.28776978417266 %\n",
      "specificity:  59.71223021582734 %\n",
      "precision:  53.6231884057971 %\n",
      "q= 11 : \n",
      "accuracy:  49.29621520175164 %\n",
      "sensitivity:  40.28776978417266 %\n",
      "specificity:  59.71223021582734 %\n",
      "precision:  53.6231884057971 %\n",
      "q= 12 : \n",
      "accuracy:  49.29621520175164 %\n",
      "sensitivity:  40.28776978417266 %\n",
      "specificity:  59.71223021582734 %\n",
      "precision:  53.6231884057971 %\n",
      "q= 13 : \n",
      "accuracy:  49.29621520175164 %\n",
      "sensitivity:  40.28776978417266 %\n",
      "specificity:  59.71223021582734 %\n",
      "precision:  53.6231884057971 %\n",
      "q= 14 : \n",
      "accuracy:  49.29621520175164 %\n",
      "sensitivity:  40.28776978417266 %\n",
      "specificity:  59.71223021582734 %\n",
      "precision:  53.6231884057971 %\n",
      "q= 15 : \n",
      "accuracy:  49.29621520175164 %\n",
      "sensitivity:  40.28776978417266 %\n",
      "specificity:  59.71223021582734 %\n",
      "precision:  53.6231884057971 %\n",
      "q= 16 : \n",
      "accuracy:  49.29621520175164 %\n",
      "sensitivity:  40.28776978417266 %\n",
      "specificity:  59.71223021582734 %\n",
      "precision:  53.6231884057971 %\n",
      "q= 17 : \n",
      "accuracy:  49.29621520175164 %\n",
      "sensitivity:  40.28776978417266 %\n",
      "specificity:  59.71223021582734 %\n",
      "precision:  53.6231884057971 %\n",
      "q= 18 : \n",
      "accuracy:  49.29621520175164 %\n",
      "sensitivity:  40.28776978417266 %\n",
      "specificity:  59.71223021582734 %\n",
      "precision:  53.6231884057971 %\n",
      "q= 19 : \n",
      "accuracy:  49.29621520175164 %\n",
      "sensitivity:  40.28776978417266 %\n",
      "specificity:  59.71223021582734 %\n",
      "precision:  53.6231884057971 %\n",
      "q= 20 : \n",
      "accuracy:  49.29621520175164 %\n",
      "sensitivity:  40.28776978417266 %\n",
      "specificity:  59.71223021582734 %\n",
      "precision:  53.6231884057971 %\n",
      "most accurate q value =  2\n"
     ]
    }
   ],
   "source": [
    "# run the function and find the best accuracy\n",
    "accuracies = []\n",
    "for i in range(1, 21): #they want accuracies between 1 and 20\n",
    "    print(\"q=\", i, \": \")\n",
    "    accuracies.append(trainEval(i, df_train, df_test))\n",
    "\n",
    "# to find the highest accuracy. Note: I initiate index counting variables to -1 to recognise potential errors\n",
    "topAcc = 0\n",
    "topQ = -1\n",
    "for i in range(0, len(accuracies)):\n",
    "    if (i > topAcc):\n",
    "        topAcc = accuracies[i]\n",
    "        topQ = i+1 # accuracies is 0 indexed so i is always 1 lower than the q value. Order used is always same\n",
    "\n",
    "print(\"most accurate q value = \", topQ)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
